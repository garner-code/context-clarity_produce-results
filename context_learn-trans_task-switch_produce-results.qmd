---
title: "context_learn-trans_task-switch_produce-results"
format: 
  html:
    code-fold: TRUE
    default-image-extension: svg
editor: visual
---

## Produce the results for Contextual clarity during training hinders learning transfer but spares task switching

This notebook provides a computationally reproducible record of the analysis and figure generation for the paper 'Contextual clarity during training hinders learning transfer but spares task switching'.

## Settings and other things

This notebook assumes you have the following file structure. Note that the pre-existing csv files were generated by the code in [this repository.](https://github.com/garner-code/doors)

``` markdown
top_folder/
│   ├── _quarto.yml
│   ├── *.Rproj
│   ├── this-qmd-doc.qmd
│   ├── R/
│   │   └── all-r-scripts.R
│   ├── data-wrangled/
│   │   └── exp_[exp_str]_evt.csv
│   │   └── exp_[exp_str]_avg.csv
│   │   └── exp_lt_maggi-k4.csv
│   ├── figs/
│   ├── res/
```

First, load required packages and set the relative paths for data and other required things...

```{r, fold=TRUE, message=FALSE, results='hide'}
options(tidyverse.quiet = TRUE)
library(tidyverse)
library(grid)
library(gridExtra)
library(knitr)
library(magick)
library(ggpubr)
library(vioplot)
library(rstatix)
library(emmeans)
library(afex)
library(pdftools)
library(purrr)
library(GGally)

data_path = 'data-wrangled/' # for all data derivs
fig_path = 'figs/' # for figures
res_path = 'res/' # for inferential results

function_loc <- "R" # where are the functions?
req_functions <- list.files(function_loc)
sapply(req_functions, function(x) source(paste(here::here(function_loc),
                                               x, sep="/")))

# # now some font settings
library(extrafont)
#font_import() # run this once only, comment out after first time
loadfonts(device='pdf')

## now some variables that will help us run code across both experiments
exp_strs <- c('lt','ts')
j_wdth <- 10 # this is for the task jumps fig
j_hgt <- j_wdth*(6/10)
trn_bp_wdth = j_wdth*.8 # this is for the knowledge onset plot
trn_bp_hgt = j_hgt

```

## Experiment One

### How did training impact task jumps?

This is where we look at the task-jumps measure between the two groups. Here I create a group x trial type dataframe and draw and save the boxplots. Note I will collect the data for both experiments here, but I will present them separately.

```{r, results='hide', message=FALSE}

# first, get the task jump data - note that I am not saving it as a csv,
# as it already exists with all the relevant info in the _avg csv
get_jump_data <- function(exp_str, data_path){
  
  tmp <- read.csv(paste(data_path, 'exp_', exp_str,
                        '_avg.csv', sep='')) %>%
    filter(ses == 2) %>%
    select(sub, train_type, context, switch, context_changes) %>%
    group_by(sub, train_type, switch) %>% 
    summarise(jumps=mean(context_changes)) %>%
    ungroup()
  tmp$exp = exp_str
  tmp
}

jumps <- do.call(rbind, lapply(exp_strs, get_jump_data,
                               data_path = data_path))

col_scheme = c('#7570b3', '#e7298a')

gen_jumps_plot(jumps,
               'jumps ~ switch*train_type', 
               exp_strs,
               col_scheme,
               j_wdth, j_hgt,
               paste(fig_path, 'task-jumps', sep=''),
               fig_labs = c('A', 'B'),
               ylabel = 'Jumps',
               xlabel = 'Group',
               ylims=c(0,5))

```

Now lets see the fig in all its glory -

![Fig 5: People in the frequent switch group broke up their routines to jump tasks](figs/task-jumps_4tlks.svg){fig-align="cent"}

Now lets apply the ANOVA model to the data -

```{r, results='hide', message=FALSE}

# first set the factors to be factors
jumps$sub <- as.factor(jumps$sub)
jumps$train_type <- as.factor(jumps$train_type)
levels(jumps$train_type) <- c('stable','variable')
jumps$switch <- as.factor(jumps$switch)
levels(jumps$switch) <- c('stay','switch')

# now run the ANOVA model
# set emmeans option to multivariate
afex_options(emmeans_model = "multivariate")
# perform the statistical model
exp_strs <- unique(jumps$exp)
tj_aovs <- lapply(exp_strs, function(x) 
  aov_ez("sub", "jumps", jumps %>% filter(exp == x), 
         within = "switch",
         between = "train_type"))
names(tj_aovs) <- exp_strs

# convert the anovas to a dataframe, save the results and show as a table
convert_aov_to_df <- function(aovl, exp_str){
  ref = aovl$anova_table
  tibble(exp = rep(exp_str, length(ref$F)),
         effect = rownames(ref),
         numDF = ref$`num Df`,
         denDF = ref$`den Df`,
         Fstat = ref$F,
         ges = ref$ges,
         p = ref$`Pr(>F)`)
}
tj_aov_dat <- do.call(rbind, 
                      lapply(1:length(exp_strs),
                             function(x) convert_aov_to_df(tj_aovs[[x]],
                                                           exp_strs[x])))
# do some manual rounding of columns
tj_aov_dat$Fstat <- round(tj_aov_dat$Fstat, 2)
tj_aov_dat$ges <- round(tj_aov_dat$ges, 3)
tj_aov_dat$p <- round(tj_aov_dat$p, 3)

# now an id column for referencing in overleaf
tj_aov_dat$id <- paste(tj_aov_dat$exp, tj_aov_dat$effect, sep="_") 
write.csv(tj_aov_dat, paste(res_path, 'task_jumps_aov.csv', sep=""), row.names=FALSE)

kable(tj_aov_dat)

```

```{r}

#| label: effect of group and switch on task jumps
#| tbl-cap: "effect of group and switch on task jumps"
kable(tj_aov_dat, digits=2)
```

We can see from the above results that we have a significant group x switch interaction for both experiments. We need to follow this up with post-hoc contrasts.

First, lets define the contrasts that we will apply to task jumps and general errors across both experiments -

```{r, message=FALSE}

train_ph_win <- list("stable_sw_v_st" = c(-1, 0, 1, 0), # switch > stay for stable group
                     "variable_sw_v_st" = c(0, -1, 0, 1))
train_ph_btwn <- list("grp_stay" = c(-1, 1, 0, 0), # var > stab
                      "grp_switch" = c(0, 0, -1, 1))

```

Now apply them to Experiment 1 task jumps, and write the output as a csv file

```{r}

tj_emm_int_lt <- emmeans(tj_aovs[["lt"]], c("train_type", "switch"))
tj_contrasts_win_lt <- contrast(tj_emm_int_lt, train_ph_win, adjust="scheffe")
tj_contrasts_btwn_lt <- contrast(tj_emm_int_lt, train_ph_btwn, adjust="scheffe")
tj_contrasts_lt <- summary(rbind(tj_contrasts_win_lt, tj_contrasts_btwn_lt))
tj_contrasts_lt$estimate <- round(tj_contrasts_lt$estimate, 2)
tj_contrasts_lt$SE <- round(tj_contrasts_lt$SE, 2)
tj_contrasts_lt$p.value <- round(tj_contrasts_lt$p.value, 2)
tj_contrasts_lt$Fstat <- round(tj_contrasts_lt$t.ratio^2, 2)

write.csv(tj_contrasts_lt, paste(res_path, 'task_jumps_post_hoc_lt.csv', sep=""), row.names=FALSE)

```

```{r}

#| label: post hoc contrasts on task jumps
#| tbl-cap: "post hoc contrasts switch on task jumps"
kable(tj_contrasts_lt, digits=2)
```

Now save the table of estimated marginal means for reporting

```{r, message=FALSE}

tj_emm_int_lt <- summary(tj_emm_int_lt)
tj_emm_int_lt$emmean <- round(tj_emm_int_lt$emmean,2)
tj_emm_int_lt$SE <- round(tj_emm_int_lt$SE,2)
tj_emm_int_lt$id <- paste(tj_emm_int_lt$train_type, tj_emm_int_lt$switch, sep="_")
write.csv(tj_emm_int_lt, paste(res_path, 'task_jumps_emms_lt.csv', sep=""), row.names=FALSE)

```

```{r}

#| label: task jump emms
#| tbl-cap: "task jump emms"
kable(tj_emm_int_lt, digits=2)
```

### How did training affect general errors?

Now we apply the same analysis as above, but to the general errors -

```{r, message=FALSE}

# get general errors data
get_error_data <- function(exp_str, data_path){
  
  tmp <- read.csv(paste(data_path, 'exp_', exp_str,
                        '_avg.csv', sep='')) %>%
    filter(ses == 2) %>%
    select(sub, train_type, context, switch, general_errors) %>%
    group_by(sub, train_type, switch) %>% 
    summarise(errors=mean(general_errors)) %>%
    ungroup()
  tmp$exp = exp_str
  tmp
}

errors <- do.call(rbind, lapply(exp_strs, get_error_data,
                                data_path = data_path))

gen_jumps_plot(errors,
               'errors ~ switch*train_type',
               exp_strs,
               col_scheme,
               j_wdth, j_hgt,
               paste(fig_path, 'general-errors', sep=''),
               fig_labs = c('C', 'D'),
               ylabel = 'Errors',
               ylims=c(0,1),
               xlabel = 'Group')

```

![Fig 5: People in the two groups showed the same levels of out of task errors](figs/general-errors_4tlks.svg){fig-align="cent"}

Next, I will put the task jumps and error figures together, for the paper.

```{r, message=FALSE}

fnms = c(paste(fig_path, 'task-jumps', sep=''), 
         paste(fig_path, 'general-errors', sep=''))

ims = lapply(fnms, function(x) image_read_pdf(paste(x, '.pdf', sep='')))

multi <- c(ims[[1]]) %>%
         image_append() %>%
        c(ims[[2]]) %>%
         image_append(stack=TRUE)
plt_hgt = j_hgt*2 # get the height of the traj plot
plt_wdth = j_wdth
pdf(paste(fig_path, 'jumps-and-errors.pdf', sep=''), width=plt_wdth,
    height=plt_hgt)
plot(multi)
dev.off()
```

```{r, results='hide', message=FALSE}

# first set the factors to be factors
errors$sub <- as.factor(errors$sub)
errors$train_type <- as.factor(errors$train_type)
levels(errors$train_type) <- c('stable','variable')
errors$switch <- as.factor(errors$switch)
levels(errors$switch) <- c('stay','switch')

# perform the statistical model
exp_strs <- unique(errors$exp)
er_aovs <- lapply(exp_strs, function(x) 
  aov_ez("sub", "errors", errors %>% filter(exp == x), 
         within = "switch",
         between = "train_type"))
names(er_aovs) <- exp_strs

er_aov_dat <- do.call(rbind, 
                      lapply(1:length(exp_strs),
                             function(x) convert_aov_to_df(er_aovs[[x]],
                                                           exp_strs[x])))

cols2round <- c("Fstat", "ges", "p")
er_aov_dat[,cols2round] <- apply(er_aov_dat[,cols2round], 2, round, 2)
er_aov_dat$id <- paste(er_aov_dat$exp, er_aov_dat$effect, sep="_")

write.csv(er_aov_dat, paste(res_path, 'gen-errs_aov.csv', sep=""), row.names=FALSE)
```

```{r}

#| label: effect of group and switch on general errors
#| tbl-cap: "effect of group and switch on general errors"
kable(er_aov_dat, digits=2)
```

We have a statistically significant main effect of switch. So let's get the EM means for that. Lets also print out the EM means for the interaction as that information is also useful.

```{r, message=FALSE}

# get emms for the main effect
ge_emm_sw_lt <- summary(emmeans(er_aovs[["lt"]], c("switch")))
# round the key variables to 2 dp
vars2round <- c("emmean", "SE")
ge_emm_sw_lt[,vars2round] <- apply(ge_emm_sw_lt[,vars2round], 2, round, 2)
# save
write.csv(ge_emm_sw_lt, paste(res_path, 'ge_emms_mesw_lt.csv', sep=""), row.names=FALSE)

# but also the numbers for the interaction, because its still useful info
ge_emm_sw_int_lt <- summary(emmeans(er_aovs[["lt"]], c("train_type","switch")))
# round
ge_emm_sw_int_lt[,vars2round] <- apply(ge_emm_sw_int_lt[,vars2round], 2, round, 2)
# make an id column
ge_emm_sw_int_lt$id <- paste(ge_emm_sw_int_lt$train_type, 
                             ge_emm_sw_int_lt$switch, sep="_")

# save
write.csv(ge_emm_sw_int_lt, paste(res_path, 'ge_emms_int_lt.csv', sep=""), row.names=FALSE)
```

```{r}

#| label: EMMs for group and switch on general errors
#| tbl-cap: "EMMs for group and switch on general errors"
kable(ge_emm_sw_int_lt, digits=2)
```

### The impact of training on learning transfer

#### Task knowledge onset

First steps are to wrangle the routine and group x transfer task data, and looking at learning onset for each group and task as a boxplot.

```{r, message=FALSE, results='hide', warning=FALSE}

###### nopw sort this code
# wrangle data
onset_dat <- read.csv(paste(data_path, 'exp_lt_maggi-k4.csv', sep='')) %>% 
  select(sid, ses, transfer, k4_onset) %>% 
  filter(ses == 3) %>%
  mutate(transfer=recode(transfer, `1` = 'comp', `2` = 'part')) 
names(onset_dat)[names(onset_dat) == "sid"] = "sub"

# now I get the group info
grp_inf <- read.csv(paste(data_path, 'exp_lt_avg.csv', sep='')) %>% 
  filter(ses == 3) %>%
  select(sub, train_type) %>%
  unique()
onset_dat <- inner_join(onset_dat, grp_inf, by='sub') %>%
                mutate(train_type=recode(train_type, `1`= 'stable', 
                                         `2` = 'variable'))
rm(grp_inf)

# some participants never learned, so we lose anyone who has a k4 of NaN,
# as that means their score was Inf
# remove participants for whom we couldn't determine learned
non_learn <- onset_dat %>% filter(is.infinite(k4_onset)) %>% 
                select(sub, train_type) %>% distinct()
onset_dat <- onset_dat %>% na.omit() %>%
                filter(is.finite(k4_onset))

# now remove subs who have less than 2 observations each
onset_dat <- inner_join(onset_dat, onset_dat %>% group_by(sub) %>%
                          summarise(N=length(sub))) %>%
               filter(N==2)

# need to show that the probability of being excluded did not relate to group membership
non_learn_prob <- binom.test(sum(non_learn$train_type == "stable"), length(non_learn$train_type), 0.5)
non_learn_prob <- tibble(n_stable = non_learn_prob$statistic,
                         n_var = non_learn_prob$parameter - non_learn_prob$statistic,
                         total = n_stable + n_var,
                         n_total = 100 - total,
                         p = round(non_learn_prob$p.value, 2),
                         id = "val")
write.csv(non_learn_prob, paste(res_path, 'non_learn_grp_mem.csv', sep=""), row.names=FALSE)

write.csv(onset_dat, paste(data_path, 'exp_lt_onset_cln.csv', sep=''), row.names=FALSE)
```

Now plot the learning onset scores -

```{r, message=FALSE}

col_scheme = c('#ccba72ff', '#4c5454ff')

k4_by_grp_fname = paste(fig_path,'k4_by_grp', sep='')
plt_tran_bp_4paper_andtlks(k4_by_grp_fname,
                trn_bp_wdth,
                trn_bp_hgt,
                onset_dat,
                'k4_onset ~ transfer*train_type', 
                col_scheme,
                'Onset',
                c(0, 200),
                fig_lab = 'A')
```

![Fig: Effect of Group and Condition on Knowledge Onset](figs/k4_by_grp_4tlks.svg){fig-align="cent"}

Now I have the data in order I am ready to perform the analysis on the onset data as defined for task jumps above, but this time on learning transfer performance.

```{r, message=FALSE, warning=FALSE}

# first set the factors to be factors
onset_dat$sub <- as.factor(onset_dat$sub)
onset_dat$train_type <- as.factor(onset_dat$train_type)
levels(onset_dat$train_type) <- c('stable','variable')
onset_dat$transfer <- as.factor(onset_dat$transfer)

onset_aov <- 
  aov_ez("sub", "k4_onset", onset_dat, 
         within = "transfer",
         between = "train_type")

lt_onset_aov_dat <- convert_aov_to_df(onset_aov, "onset")
# do some manual rounding of columns
lt_onset_aov_dat$Fstat <- round(lt_onset_aov_dat$Fstat, 2)
lt_onset_aov_dat$ges <- round(lt_onset_aov_dat$ges, 3)
lt_onset_aov_dat$p <- round(lt_onset_aov_dat$p, 3)

# now save
write.csv(lt_onset_aov_dat, paste(res_path, 'lt_onset_aov.csv', sep=""), row.names=FALSE)

```

```{r}

#| label: Effect of group and transfer condition on knowledge onset
#| tbl-cap: "Effect of group and transfer condition on knowledge onset"
kable(lt_onset_aov_dat, digits=2)
```

There are significant main effects of condition, so lets get the estimated marginal means -

```{r, message=FALSE}

# get emms for the main effect
lt_onset_emm <- summary(emmeans(onset_aov, c("transfer")))

cols2round <- c("emmean", "SE")
lt_onset_emm[,cols2round] <- apply(lt_onset_emm[,cols2round], 2, round, 2)
write.csv(lt_onset_emm, paste(res_path, 'lt_onset_emm_transfer.csv', sep=""), row.names=FALSE)
```

```{r}

#| label: EMMs for transfer condition on knowledge onset
#| tbl-cap: "EMMs for transfer condition on knowledge onset"
kable(lt_onset_emm, digits=2)
```

There is a significant group x condition interaction, so lets follow up -

```{r, message=FALSE}

lt_onset_int_emm <- emmeans(onset_aov, c("train_type", "transfer"))

# copy the contrasts used for the task jump analysis and rename for current purposes
# You can use these across all measures
lt_ph_win_contrasts <- train_ph_win
lt_ph_win_contrasts$stable_comp_vs_mix <- lt_ph_win_contrasts$stable_sw_v_st
lt_ph_win_contrasts$variable_comp_vs_mix <- lt_ph_win_contrasts$variable_sw_v_st
lt_ph_win_contrasts$stable_sw_v_st <- NULL
lt_ph_win_contrasts$variable_sw_v_st <- NULL

lt_ph_btwn_contrasts <- train_ph_btwn
lt_ph_btwn_contrasts$grp_comp <- lt_ph_btwn_contrasts$grp_stay
lt_ph_btwn_contrasts$grp_mix <- lt_ph_btwn_contrasts$grp_switch
lt_ph_btwn_contrasts$grp_stay <- lt_ph_btwn_contrasts$grp_switch <- NULL
################################################################################

lt_onset_win <- contrast(lt_onset_int_emm, lt_ph_win_contrasts, adjust="scheffe")
lt_onset_btwn <- contrast(lt_onset_int_emm, lt_ph_btwn_contrasts, adjust="scheffe")
lt_onset_contrasts <- summary(rbind(lt_onset_win, lt_onset_btwn))

lt_onset_contrasts$estimate <- round(lt_onset_contrasts$estimate, 2)
lt_onset_contrasts$SE <- round(lt_onset_contrasts$SE, 2)
lt_onset_contrasts$p.value <- round(lt_onset_contrasts$p.value, 2)
lt_onset_contrasts$Fstat <- round(lt_onset_contrasts$t.ratio^2, 2)

write.csv(lt_onset_contrasts, paste(res_path, 'lt_onset_int_ph.csv', sep=""), row.names=FALSE)

# now also save the emms for the interaction
lt_onset_int_emm <- summary(lt_onset_int_emm)
lt_onset_int_emm[,cols2round] <- apply(lt_onset_int_emm[,cols2round], 2, round, 2)
lt_onset_int_emm$id <- paste(lt_onset_int_emm$train_type, lt_onset_int_emm$transfer, sep="_")
write.csv(lt_onset_int_emm, paste(res_path, 'lt_onset_int_emm.csv', sep=""), row.names=FALSE)
```

```{r}

# | label: EMMs for group by transfer condition on knowledge onset
# | tbl-cap: "EMMs for group by transfer condition on knowledge onset"
kable(lt_onset_int_emm, digits=2)
```

```{r}

# | label: EMMs for group by transfer condition on knowledge onset
# | tbl-cap: "EMMs for group by transfer condition on knowledge onset"
kable(lt_onset_int_emm, digits=2)
```

#### Accuracy data

Now I wrangle the accuracy data so I can apply the same analysis.

```{r}

lt_acc <- read.csv(paste(data_path, 'exp_lt_avg.csv', sep='')) %>% 
  filter(ses==3) %>%
  select(sub, transfer, full_transfer_first, train_type, accuracy) %>% 
  mutate(train_type=recode(train_type, `1` = 'stable', `2` = 'variable'),
         transfer=recode(transfer, `1` = 'identity', `2` = 'mixed'))
```

So now we have the data, we can plot it

```{r}


# now I can plot the data
lt_acc_by_grp_fname = paste(fig_path,'lt_acc_by_grp', sep='')
plt_tran_bp_4paper_andtlks(lt_acc_by_grp_fname,
                trn_bp_wdth,
                trn_bp_hgt,
                lt_acc,
                'accuracy ~ transfer*train_type', 
                col_scheme,
                'Accuracy',
                c(0.6, 1),
                fig_lab = 'B')
```

![Fig: Effect of Group and Condition on Accuracy](figs/lt_acc_by_grp_4tlks.svg){fig-align="cent"}

```{r, message=FALSE}

# first set the factors to be factors
lt_acc$sub <- as.factor(lt_acc$sub)
lt_acc$train_type <- as.factor(lt_acc$train_type)
levels(lt_acc$train_type) <- c('stable','variable')
lt_acc$transfer <- as.factor(lt_acc$transfer)

lt_acc_aov <- 
  aov_ez("sub", "accuracy", lt_acc, 
         within = "transfer",
         between = "train_type")

lt_acc_aov_dat <- convert_aov_to_df(lt_acc_aov, "lt_acc")
# do some manual rounding of columns
lt_acc_aov_dat$Fstat <- round(lt_acc_aov_dat$Fstat, 2)
lt_acc_aov_dat$ges <- round(lt_acc_aov_dat$ges, 3)
lt_acc_aov_dat$p <- round(lt_acc_aov_dat$p, 3)

# now save
write.csv(lt_acc_aov_dat, paste(res_path, 'lt_acc_aov.csv', sep=""), row.names=FALSE)

```

There is a significant main effect of condition, so lets get the estimated marginal means -

```{r, message=FALSE}

# get emms for the main effect
lt_acc_emm <- summary(emmeans(lt_acc_aov, c("transfer")))

cols2round <- c("emmean", "SE")
lt_acc_emm[,cols2round] <- apply(lt_acc_emm[,cols2round], 2, round, 2)
write.csv(lt_acc_emm, paste(res_path, 'lt_acc_emm_transfer.csv', sep=""), row.names=FALSE)
```

```{r}

#| label: EMMs for transfer condition on accuracy
#| tbl-cap: "EMMs for transfer condition on accuracy"
kable(lt_acc_emm, digits=2)
```

Now I follow up the group x transfer interaction

```{r}

lt_acc_int_emm <- emmeans(lt_acc_aov, c("train_type", "transfer"))

################################################################################

lt_acc_win <- contrast(lt_acc_int_emm, lt_ph_win_contrasts, adjust="scheffe")
lt_acc_btwn <- contrast(lt_acc_int_emm, lt_ph_btwn_contrasts, adjust="scheffe")
lt_acc_contrasts <- summary(rbind(lt_acc_win, lt_acc_btwn))

lt_acc_contrasts$estimate <- round(lt_acc_contrasts$estimate, 2)
lt_acc_contrasts$SE <- round(lt_acc_contrasts$SE, 2)
lt_acc_contrasts$p.value <- round(lt_acc_contrasts$p.value, 2)
lt_acc_contrasts$Fstat <- round(lt_acc_contrasts$t.ratio^2, 2)

write.csv(lt_acc_contrasts, paste(res_path, 'lt_acc_int_ph.csv', sep=""), row.names=FALSE)

# now also save the emms for the interaction
lt_acc_int_emm <- summary(lt_acc_int_emm)
lt_acc_int_emm[,cols2round] <- apply(lt_acc_int_emm[,cols2round], 2, round, 2)
lt_acc_int_emm$id <- paste(lt_acc_int_emm$train_type, lt_acc_int_emm$transfer, sep="_")
write.csv(lt_acc_int_emm, paste(res_path, 'lt_acc_int_emm.csv', sep=""), row.names=FALSE)
```

```{r}
# | label: EMMs for group by transfer condition on knowledge onset
# | tbl-cap: "EMMs for group by transfer condition on knowledge onset"
kable(lt_acc_contrasts, digits=2)
```

#### Setting errors

Okies. That is the accuracy measure done. Now I can measure setting errors, defined as selections during transfer, that were relevant during training, that are not relevant now.

```{r, message=FALSE}

set_err <- read.csv(paste(data_path, 'exp_lt_evt.csv', sep='')) %>%
              filter(ses >= 2) 

# this function ius ugly, but does the job
get_other_doors <- function(set_err, subj){
  # get the doors that would count as 'setting errors'
  sess2_doors <- set_err %>% filter(ses == 2, 
                                    sub == subj) %>% 
                select(sub, door, context, door_cc) %>%
                filter(as.logical(door_cc)) %>%
                distinct() %>% select(sub, door, context)
  
  sess3_doors <- set_err %>% filter(ses == 3, 
                                    sub == subj) %>%
                  select(sub, door, context, door_cc) %>%
                  filter(as.logical(door_cc)) %>%
                  distinct() %>% select(sub, door, context) 
  
  other_doors <- sess3_doors %>% group_by(context) %>% mutate(other=sess2_doors$door[!sess2_doors$door %in% door])
  
  # now bind the new doors to the subject's data
  dat <- set_err %>% filter(sub == subj,
                            ses == 3)
  dat$door_oc <- NA
  dat$door_oc[dat$context == 3 & dat$door %in% other_doors$other[other_doors$context == 3]] = 1
  dat$door_oc[dat$context == 4 & dat$door %in% other_doors$other[other_doors$context == 4]] = 1
  dat$door_oc[is.na(dat$door_oc)] <- 0
  dat
}

subs <- unique(set_err$sub)
lt_set_err_dat <- do.call(rbind, lapply(subs, get_other_doors, set_err=set_err)) %>%
                    group_by(sub, train_type, transfer) %>%
                    summarise(set_err = mean(door_oc)) %>%
                    ungroup()
```

Now I have the setting errors, I can plot them -

```{r}

# now I can plot the data
lt_se_by_grp_fname = paste(fig_path,'lt_se_by_grp', sep='')

plt_tran_bp_4paper_andtlks(lt_se_by_grp_fname,
                trn_bp_wdth,
                trn_bp_hgt,
                lt_set_err_dat,
                'set_err ~ transfer*train_type', 
                col_scheme,
                'SE',
                c(0, 0.8),
                fig_lab = 'C')
```

![Fig: Effect of Group and Condition on Setting Errors](figs/lt_se_by_grp_4tlks.svg){fig-align="cent"}

Now we have a plot, we can analyse the data

```{r, message=FALSE}
# first set the factors to be factors
lt_set_err_dat$sub <- as.factor(lt_set_err_dat$sub)
lt_set_err_dat$train_type <- as.factor(lt_set_err_dat$train_type)
levels(lt_set_err_dat$train_type) <- c('stable','variable')
lt_set_err_dat$transfer <- as.factor(lt_set_err_dat$transfer)
levels(lt_set_err_dat$transfer) <- c('id','mix')

lt_set_err_aov <- 
  aov_ez("sub", "set_err", lt_set_err_dat, 
         within = "transfer",
         between = "train_type")

lt_set_err_aov_dat <- convert_aov_to_df(lt_set_err_aov, "lt_se")
# do some manual rounding of columns
lt_set_err_aov_dat$Fstat <- round(lt_set_err_aov_dat$Fstat, 2)
lt_set_err_aov_dat$ges <- round(lt_set_err_aov_dat$ges, 3)
lt_set_err_aov_dat$p <- round(lt_set_err_aov_dat$p, 3)

# now save
write.csv(lt_set_err_aov_dat, paste(res_path, 'lt_se_aov.csv', sep=""), row.names=FALSE)
```

```{r}

# | label: Effect of group by transfer condition on setting error during test
# | tbl-cap: "Effect of group by transfer condition on setting error during test"
kable(lt_set_err_aov_dat, digits=2)
```

Ok, now lets get the EMMs...

```{r}

lt_set_err_int <-summary(emmeans(lt_set_err_aov, c("train_type", "transfer")))
lt_set_err_int[,cols2round] <- apply(lt_set_err_int[,cols2round], 2, round, 2)
write.csv(lt_set_err_int, paste(res_path, 'lt_se_emm_int.csv', sep=""), row.names=FALSE)
```

```{r}


# | label: EMMs for group by transfer condition on setting error during test
# | tbl-cap: "EMMs for group by transfer condition on setting error during test"
kable(lt_set_err_int, digits=2)
```

#### General errors

Now we see whether people were selecting doors that belonged to neither task, more often during the test phase. First I load in the setting error data, and then recode the general error data with respect to the newly defined setting errors.

```{r, message=FALSE, warning=FALSE}

lt_gen_err_dat <- do.call(rbind, lapply(subs, get_other_doors, set_err=set_err)) %>%
   mutate(door_nc = case_when(door_nc == 1 & door_oc == 1 ~ 0,
                              door_nc == 1 & door_oc == 0 ~ 1,
                              door_nc == 0 ~ 0)) %>%                    
  group_by(sub, train_type, transfer) %>%
                    summarise(gen_err = mean(door_nc)) %>%
                    ungroup()
  
```


Lets plot these general errors -


```{r}

# now I can plot the data
lt_ge_by_grp_fname = paste(fig_path,'lt_ge_by_grp', sep='')

plt_tran_bp_4paper_andtlks(lt_ge_by_grp_fname,
                trn_bp_wdth,
                trn_bp_hgt,
                lt_gen_err_dat,
                'gen_err ~ transfer*train_type', 
                col_scheme,
                'GE',
                c(0, 0.8),
                fig_lab = 'D')

```


![Fig: Effect of Group and Condition on Knowledge Onset](figs/lt_ge_by_grp_4tlks.svg){fig-align="cent"}

Now I have this, I can analyse the general errors...

```{r, message=FALSE, warning=FALSE}

# first set the factors to be factors
lt_gen_err_dat$sub <- as.factor(lt_gen_err_dat$sub)
lt_gen_err_dat$train_type <- as.factor(lt_gen_err_dat$train_type)
levels(lt_gen_err_dat$train_type) <- c('stable','variable')
lt_gen_err_dat$transfer <- as.factor(lt_gen_err_dat$transfer)
levels(lt_gen_err_dat$transfer) <- c('id','mix')

lt_gen_err_aov <- 
  aov_ez("sub", "gen_err", lt_gen_err_dat, 
         within = "transfer",
         between = "train_type")

lt_gen_err_aov <- convert_aov_to_df(lt_gen_err_aov, "lt_ge")
# do some manual rounding of columns
lt_gen_err_aov$Fstat <- round(lt_gen_err_aov$Fstat, 2)
lt_gen_err_aov$ges <- round(lt_gen_err_aov$ges, 3)
lt_gen_err_aov$p <- round(lt_gen_err_aov$p, 3)

# now save
write.csv(lt_gen_err_aov, paste(res_path, 'lt_se_aov.csv', sep=""), row.names=FALSE)


```

```{r, message=FALSE, warning=FALSE}


# | label: Effect of group by transfer condition on general errors during test
# | tbl-cap: "Effect of group by transfer condition on general errors during test"
kable(lt_gen_err_aov, digits=2)
```


Then I join up the figs for the paper.


```{r, message=FALSE}

fnms = c(paste(fig_path, 'k4_by_grp', sep=''), 
         paste(fig_path, 'lt_acc_by_grp', sep=''),
         paste(fig_path, 'lt_se_by_grp', sep=''), 
         paste(fig_path, 'lt_ge_by_grp', sep=''))

ims = lapply(fnms, function(x) image_read_pdf(paste(x, '.pdf', sep='')))

top <- c(ims[[1]], ims[[2]]) %>%
         image_append(stack = FALSE)
bottom <- c(ims[[3]], ims[[4]]) %>%
         image_append(stack=FALSE) 
multi <- c(top, bottom) %>% image_append(stack=TRUE)
       
plt_hgt = j_hgt*2 # get the height of the traj plot
plt_wdth = j_wdth*2
pdf(paste(fig_path, 'lt_results.pdf', sep=''), width=plt_wdth,
    height=plt_hgt)
plot(multi)
dev.off()
```
